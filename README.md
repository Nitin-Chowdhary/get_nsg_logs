# Reading NSG logs from Blob Storage

You might have set your Azure Vnet, with some NSGs. You start rolling apps, to the point where you have many VMs, and many NSGs. Somebody makes an application upgrade, or installs a new application, but traffic is not flowing through. Which NSG is dropping traffic? Which TCP ports should be opened?

One possibility is using Traffic Analytics. Traffic Analytics is a two-step process:
1. NSG logs are stored in a storage account
2. NSG logs from the storage account are processed (consolidated and enriched with additional information) and made queriable

One of the nicest features of Traffic Analytics is being able to query logs with the KQL (Kusto Query Language). For example, you can use this query to find out the dropped flows in the last 3 hours for IP address 1.2.3.4:

```
AzureNetworkAnalytics_CL
| where TimeGenerated >= ago(1h)
| where SubType_s == "FlowLog"
| where DeniedInFlows_d > 0 or DeniedOutFlows_d > 0
| where SrcIP_s == "1.2.3.4"
| project NSGName=split(NSGList_s, "/")[2],NSGRules_s,DeniedInFlows_d,DeniedOutFlows_d,SrcIP_s,DestIP_s,DestPort_d,L7Protocol_s
```

However, you will notice that there is a time lag, and you will not find the very latest logs in Log Analytics. The original NSG Flow logs are stored in storage account, in JSON format, so you could get those logs using the Azure Storage SDK.

You can use the Python script in this repository (assuming you have the Python SDK for storage installed). You can use different flags, like the --help option to get usage information. If you do not have handy a Python console you can use Azure Cloud Shell and clone this repository:

```
git clone https://github.com/erjosito/get_nsg_logs
```

You might to install the Python module for Azure Storage:

```
 pip install azure-storage --user 
```
Now you can have a look at the different options:

```
$ cd ./get_nsg_logs/
$ python3 ./get_nsg_logs.py --help
usage: get_nsg_logs.py [-h] [--account-name ACCOUNT_NAME] [--display-lb]
                       [--display-allowed]
                       [--display-direction DISPLAY_DIRECTION]
                       [--display-hours DISPLAY_HOURS] [--version VERSION]
                       [--only-non-zero] [--flow-state FLOW_STATE_FILTER]
                       [--ip IP_FILTER] [--port PORT_FILTER]
                       [--nsg-name NSG_NAME_FILTER] [--aggregate] [--verbose]

Get the latest flow logs in a storage account

optional arguments:
  -h, --help            show this help message and exit
  --account-name ACCOUNT_NAME
                        you need to supply an storage account name. You can
                        get a list of your storage accounts with this command:
                        az storage account list -o table
  --display-lb          display or hide flows generated by the Azure LB
                        (default: False)
  --display-allowed     display as well flows allowed by NSGs (default: False)
  --display-direction DISPLAY_DIRECTION
                        display flows only in a specific direction. Can be in,
                        out, or both (default in)
  --display-hours DISPLAY_HOURS
                        How many hours to look back (default: 1)
  --version VERSION     NSG flow log version (1 or 2, default: 1)
  --only-non-zero       display only v2 flows with non-zero packet/byte
                        counters (default: False)
  --flow-state FLOW_STATE_FILTER
                        filter the output to a specific v2 flow type (B/C/E)
  --ip IP_FILTER        filter the output to a specific IP address
  --port PORT_FILTER    filter the output to a specific TCP/UDP port
  --nsg-name NSG_NAME_FILTER
                        filter the output to a specific NSG
  --aggregate           run in verbose mode (default: False)
  --verbose             run in verbose mode (default: False)
  ```

There is something you need to do before being able to access Azure Blob Storage: finding out the Azure Storage Account key. The script will read it from the environtment variable STORAGE_ACCOUNT_KEY, that you can set with this command:

```
export STORAGE_ACCOUNT_KEY=$(az storage account keys list -n your_storage_account_name --query [0].value -o tsv)
```

For example, in order to show dropped and allowed traffic of ingress NSG logs stored in the storage account `ernetworkhubdiag857`, excluding Azure LB probe traffic for the last 6 hours:

```
$ python3 ./get_nsg_logs.py --accountName ernetworkhubdiag857 --displayHours 6 --displayDirection in --displayAllowed
2018-09-21T09:49:57.3055150Z NVA-NSG DefaultRule_AllowVnetInBound A I 10.90.15.47 29014 10.139.149.70 23
2018-09-21T09:49:57.3055150Z NVA-NSG DefaultRule_AllowVnetInBound A I 10.90.15.47 29014 10.139.149.70 23
2018-09-21T09:49:57.3055150Z NVA-NSG DefaultRule_AllowVnetInBound A I 10.90.15.47 32069 10.139.149.70 23
2018-09-21T09:49:57.3055150Z NVA-NSG DefaultRule_AllowVnetInBound A I 10.90.15.47 29014 10.139.149.70 23
2018-09-21T09:49:57.3055150Z NVA-NSG DefaultRule_AllowVnetInBound A I 10.90.15.47 29014 10.139.149.70 23
2018-09-21T09:49:57.3055150Z NVA-NSG DefaultRule_AllowVnetInBound A I 10.90.15.47 32069 10.139.149.70 23
```

If you are using the version 2 of the flow log export format, you can show some additional options:

```
$ python3 ./get_nsg_logs.py --account-name fwtestdiag354 --version 2 --display-allowed --display-direction both --only-non-zero --port 80 --display-hours 2 --aggregate
2019-10-16T22:20:16.9434260Z FWTESTVM-NSG DefaultRule_AllowInternetOutBound A O 192.168.1.4 tcp 39884 104.28.19.94 80 E src2dst: 6/419 dst2src: 4/629
2019-10-16T21:32:16.8646597Z FWTESTVM-NSG DefaultRule_AllowInternetOutBound A O 192.168.1.4 tcp 54326 51.137.52.221 80 E src2dst: 17/1787 dst2src: 120/172007
2019-10-16T21:32:16.8646597Z FWTESTVM-NSG DefaultRule_AllowInternetOutBound A O 192.168.1.4 tcp 34680 91.189.88.24 80 E src2dst: 25/1875 dst2src: 66/93416
Totals src2dst -> 48 packets and 4081 bytes
Totals dst2src -> 190 packets and 266052 bytes
```